{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classify_Archive_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VwELbWoKxe4"
      },
      "source": [
        "# Asteroid Hunter - Classify Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLUeF7E0F9JE"
      },
      "source": [
        " \n",
        "This Code is used to classify images using an already trained model hosted in Google Cloud AutoML Vision (Asteroid Hunter Project).\n",
        "\n",
        "**This code has been created to be run using Gooogle Colab.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAv2wp4SGOg-"
      },
      "source": [
        "\n",
        "We start with a pip cell. This package is missing from the default Google Colab library pack (remeber to click on \"restart runtime\" in the cell's output)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQULUJnPWOOf"
      },
      "source": [
        "!pip install --upgrade google-cloud-automl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y3qRCVqK7qM"
      },
      "source": [
        "**To set the os.environ a few cells below, you need a json file provided by the project team**. This file must be placed in the same folder as the code. If you are using Google Colab, just click on \"upload\", import it and it will be directly stored in the main root folder ('content')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqZGlNZ9Wrpc"
      },
      "source": [
        "from google.cloud import automl\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "os.makedirs('/content/images_to_classify/', exist_ok = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhCrYh6clWON"
      },
      "source": [
        "Now, let's login to Google Cloud using your Gmail account. The bucket where the images to classify will be stored is public so any Gmail account should work. Steps:\n",
        "\n",
        "1) Login to gmail using another tab of the same web browser. If you are using Google Colab this step can be skipped, you are already logged in with a Gmail account. \n",
        "\n",
        "2) Launch the cell below and click on the link. Accept the Google Cloud conditions.\n",
        "\n",
        "3) Once you have accepted, a login code will be provided. Copy this code and paste it into the case from provided by this case.\n",
        "\n",
        "Ignore the warning appearing as an output from the second cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2dO69ZiX9wS"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NGpn-K0X-te"
      },
      "source": [
        "project_id = 'hst-asteroid-detection'\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gze5qB0dNT3"
      },
      "source": [
        "Now just upload the images you want to classify to the \"images_to_classify\" folder. If you are using Google Colab and you are not able to see this folder yet, click on the \"folder refresh\" icon  from the files menu in the left part of the screen.\n",
        "\n",
        "To upload the files, click on the \"3 dots\" icon at the right part of the folder name and choose \"upload\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byi9nZ77nLyh"
      },
      "source": [
        "#Copy to Google Cloud the files to classify\n",
        "\n",
        "copy1 = subprocess.Popen('gsutil -m cp -r /content/images_to_classify/ gs://hst-satellites-public/', shell=True, stdout=subprocess.PIPE)\n",
        "copy1.wait()\n",
        "\n",
        "#Create the csv needed by AutoML\n",
        "\n",
        "images_list = !gsutil ls gs://hst-satellites-public/images_to_classify/\n",
        "the_list = pd.DataFrame(images_list)\n",
        "the_list.to_csv('images.csv', header=False, index=False)\n",
        "\n",
        "copy2 = subprocess.Popen('gsutil cp  images.csv gs://hst-satellites-public/', shell=True, stdout=subprocess.PIPE)\n",
        "copy2.wait()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo3FYl0pMA4y"
      },
      "source": [
        "# Batch Classification\n",
        "\n",
        "And now we just launch our images classification. \n",
        "\n",
        "It will take between 45 minutes (this is the  built-in minimum for AutoML Batch Classification) and several hours depending on the amount of images uploaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VpS9jXPeWHf3"
      },
      "source": [
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/content/hst-asteroid-detection-ae7516235f0b.json\"\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"]=\"hst-asteroid-detection\"\n",
        "\n",
        "# Variables\n",
        "project_id = \"129924192384\"\n",
        "model_id= \"IOD5322289388342738944\"\n",
        "input_uri = \"gs://hst-satellites-public/images.csv\"\n",
        "output_uri = \"gs://hst-satellites-public/output/\"\n",
        "\n",
        "prediction_client = automl.PredictionServiceClient()\n",
        "\n",
        "starttime = time.time()\n",
        "\n",
        "    # Get the full path of the model.\n",
        "model_full_id = f\"projects/{project_id}/locations/us-central1/models/{model_id}\"\n",
        "\n",
        "gcs_source = automl.GcsSource(input_uris=[input_uri])\n",
        "\n",
        "input_config = automl.BatchPredictInputConfig(gcs_source=gcs_source)\n",
        "gcs_destination = automl.GcsDestination(output_uri_prefix=output_uri)\n",
        "output_config = automl.BatchPredictOutputConfig(\n",
        "gcs_destination=gcs_destination\n",
        "    )\n",
        "\n",
        "params = {\"score_threshold\": \"0.5\"}\n",
        "\n",
        "response = prediction_client.batch_predict(\n",
        "    name=model_full_id,\n",
        "    input_config=input_config,\n",
        "    output_config=output_config,\n",
        "    params = params\n",
        "    )\n",
        "\n",
        "print(\"Waiting for operation to complete...\")\n",
        "print(\n",
        "        f\"Batch Prediction results saved to Cloud Storage bucket. {response.result()}\"\n",
        "    )\n",
        "\n",
        "print('That took {} seconds'.format(time.time() - starttime))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORn_mAGcnHBq"
      },
      "source": [
        "Once the classification is finished, we import the results from Google Cloud. You will find the results in several json files inside the \"output\" folder using the file management tab.\n",
        "\n",
        "Inside the json files you will find (among other data) the label, score and the corners of the bounding box for the different objects detected in the uploaded images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t4eGPySnEZN"
      },
      "source": [
        "copy1 = subprocess.Popen('gsutil -m cp -r gs://hst-satellites-public/output/ . ', shell=True, stdout=subprocess.PIPE)\n",
        "copy1.wait()\n",
        "\n",
        "subprocess.Popen('gsutil rm -r gs://hst-satellites-public/images.csv', shell=True, stdout=subprocess.PIPE)\n",
        "subprocess.Popen('gsutil rm -r gs://hst-satellites-public/output/', shell=True, stdout=subprocess.PIPE)\n",
        "subprocess.Popen('gsutil rm -r gs://hst-satellites-public/images_to_classify/', shell=True, stdout=subprocess.PIPE)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}